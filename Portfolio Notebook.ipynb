{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Notebook\n",
    "Cheng Zhong <br>\n",
    "cheng.zhong@columbia.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook summarizes three machine learning projects I conducted in Spring 2021 for the advanced machine learning class at Columbia University. These projects analyzes real-world probelms with deep learning and neural networks algorithms. Different types of data were adopted, including tabular, image, and text data. Supervised machine learning models were applied to select key features, identify patterns, and generate evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1: Predict World Happiness Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link to project:** https://github.com/chengzhong666/Advanced-Machine-Learning-Portfolio/blob/main/Project%201%20-%20Predict%20World%20Happiness%20Rankings/Predicting%20Happiness-Cheng%20Zhong.ipynb\n",
    "\n",
    "**Research questions:**\n",
    "- What makes the citizens of one country more happy than the citizens of other countries?\n",
    "- Do variables measuring perceptions of corruption, GDP, maintaining a healthy lifestyle, or social support associate with a country's happiness ranking?\n",
    "\n",
    "**Data source:** 2019 World Happiness Survey Rankings (https://worldhappiness.report/)\n",
    "\n",
    "**Data type:** Tabular data\n",
    "\n",
    "**Features:**\n",
    "*   Country or region\n",
    "*   GDP per capita\n",
    "*   Social support\n",
    "*   Healthy life expectancy\n",
    "*   Freedom to make life choices\n",
    "*   Generosity\n",
    "*   Perceptions of corruption\n",
    "\n",
    "**Target:**\n",
    "*   Happiness_level (Very High = Top 20% and Very Low = Bottom 20%)\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "To understand how the features listed above influence on the happiness level, I've experimented with logistic regression, penalized logistic regression, k-nearest neighbors, random forest, and neural networks with keras models to select some of the most impactful features. Since the dataset is listed by country, the total length of data is 156. The size is even smaller after splitting the train and test sets, which may have a negative influence on training the models. After scaling the data, I adopted GridSearch cross validation to tune hyperparameters for each models. For instance, C for logistic regressions, k neighbors for KNN model, and nodes and learning rate for keras models.\n",
    "\n",
    "My best performing model is a keras model with an accuracy of 0.4615 and loss of 1.2060. The structure of the model is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 9,413\n",
      "Trainable params: 9,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Predict Covid Positivity from X-Ray Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link to project:** https://github.com/chengzhong666/Advanced-Machine-Learning-Portfolio/blob/main/Project%202%20-%20Predict%20Covid%20Positivity%20from%20X-Ray%20Image/Covid.ipynb\n",
    "\n",
    "**Research goal:** Classify X-ray images into three categories: 1) Covid pneumonia, 2) non-covid pneumonia, and 3) normal.\n",
    "\n",
    "\n",
    "**Data source:** M.E.H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M.A. Kadir, Z.B. Mahbub, K.R. Islam, M.S. Khan, A. Iqbal, N. Al-Emadi, M.B.I. Reaz, “Can AI help in screening Viral and COVID-19 pneumonia?” arXiv preprint, 29 March 2020, https://arxiv.org/abs/2003.13145\n",
    "\n",
    "**Data type:** Image data\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "From the beginning of 2020, coronavirus (COVID-19) has been seriously endangering people's health and lives. It is significant to correctly identify patients who are infected. Chest X-ray images have been an important evidence to diagnose positive cases. By applying convolutional neural network and transfer learning methods, the diagnostic accuracy could be improved. Medical workers, scientists, and policy-makers could advance their analytical judgements and optimize their decisions.\n",
    "\n",
    "After preprocessing the image data, I experimented with three models:\n",
    "- Model 1: Keras convolutional neural network (accuracy: 0.9460)\n",
    "- Model 2: Keras convolutional neural network (accuracy: 0.9447)\n",
    "           second convoutional layer w/ kernal size = 3\n",
    "           initiate reduceLROnPlateau to avoid overfitting\n",
    "- Model 3: Transfer learning VGG16 model (accuracy: 0.9523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 192, 192, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 192, 192, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 192, 192, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 96, 96, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 96, 96, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 48, 48, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 33,593,155\n",
      "Trainable params: 18,878,467\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16 \n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = VGG16(input_shape=(192,192,3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False \n",
    "flat = Flatten()(base_model.layers[-1].output)\n",
    "class_ = Dense(1024, activation='relu')(flat)\n",
    "output = Dense(3, activation='softmax')(class_)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Predict Covid Tweets Misinformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link to project:** https://github.com/chengzhong666/Advanced-Machine-Learning-Portfolio/blob/main/Project%203%20-%20Predict%20Covid%20Tweets%20Misinformation/covid%20misinformation.ipynb\n",
    "\n",
    "**Research goal:** Classify X-ray images into three categories: 1) Covid pneumonia, 2) non-covid pneumonia, and 3) normal.\n",
    "\n",
    "**Data source:** Shahi, Gautam Kishore, Anne Dirkson, and Tim A. Majchrzak. \"An exploratory study of covid-19 misinformation on twitter.\" Online Social Networks and Media 22 (2021): 100104 (\"https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv\")\n",
    "\n",
    "**Data type:** Text data\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "This dataset contains text data on covid-19 information tweets. The labels for the tweets are two categories, real and false. Building a predictive model using that is practically useful for identifying the truthfulness of information. It could improve the efficiency for the public to adopt correct knowledge for covid and prevent the spread of rumors.\n",
    "\n",
    "The text data reflect different patterns for true and false tweets. For instance, veracious tweets generally show a neutral tone, use informative language, and avoid hateful speech. On the other hand, false news tweets show their inflammatory nature, deny scientific approaches to fight over the pandemic, and incite ignorance and hatred.\n",
    "\n",
    "By applying deep learning algorithms to this dataset, these patterns of real and false tweets could be analyzed and identified in a relatively automated way. The models generated could be used for future inputs, and the decision makers could predict future trends and regulations and optimize resources.\n",
    "\n",
    "After preprocessing the text data, I experimented with four models:\n",
    "- Model 1: 1 embedding layer + 2 LSTM layers (accuracy: 0.9411)\n",
    "- Model 2: 1 embedding layer + 2 LSTM layers w/ dropout regularization on the second layer (accuracy: 0.9393)\n",
    "- Model 3: 1 embedding layer + 1 conv 1D layer + 2 LSTM layers w/ dropout regularization on the second LSTM layer (accuracy: 0.9369)\n",
    "- Model 4: 1 embedding layer + 1 bidirectional LSTM layer + 1 LSTM layer with dropout regularization (accuracy: 0.9472)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(10000, 100, input_length=40))\n",
    "model3.add(Bidirectional(LSTM(40, activation='tanh', return_sequences=True)))\n",
    "model3.add(LSTM(60, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))\n",
    "model3.add(Dense(40, activation='relu'))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please feel free to reach out through my email if you want to talk about these projects. Thank you! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
